

%% See "book", "report", "letter" for other types of document.
\documentclass[11pt,a4paper]{article}
%\documentclass[11pt,a4paper]{article} % use larger type; default would be 10pt

%% Packages
\usepackage{lipsum} % to get some dummy text
\usepackage[utf8]{inputenc} % set input encoding 
%\usepackage[francais]{babel} %accens aigus accept√©s dans le texte
\usepackage{hyperref} % for web links
\usepackage{amssymb, amsmath, amsfonts} % symbols math (\mathbb etc...).
\usepackage{geometry} % for page dimensions, landscape, format
\usepackage{fancyhdr}
\usepackage{enumerate} % to be able to determine the style of the enumeration
%\usepackage[toc,page]{appendix} % For appendices
%\usepackage[final]{pdfpages} % to include a pdf

%% Definition of the environment for a diary
\newenvironment{loggentry}[2]% date, heading
{\noindent\textbf{#1}\hspace{1cm}$\mathbf{\sim}$\text{ }\textbf{#2}\\}{\vspace{0.5cm}}


%% Page dimensions, landscape format
%\geometry{legalpaper, margin=1in} % c.f. doc package geometry


%% Headers and footers
%% This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{1pt} % customise the layout...
\lhead{}\chead{}\rhead{Aritz Bercher}
\lfoot{}\cfoot{\thepage}\rfoot{}

%% Title

\title{Chat bots and virtual assistants\\ Journal}
\author{Aritz Bercher}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
I find the topic of chat bots and virtual assistants really cool. I will try to gather here some information found on the web.
\end{abstract}

\section{Virtual Assistant Design}

\subsection{Limitations of current bots/Differences with human behavior}

In this section, I will try to list current limitations that the bots seem to have. Typically things that humans would do right but that bots do wrong:
\begin{enumerate}
\item (30.06.19) Virtual assistants aren't able to \textbf{recognize the mood of the user} and adapt their behaviour in consequence.
\item (17.05.19) A bot doesn't seem to have \textbf{general knowledge of the world}. If something goes out of its domain, it has no clue what to do, and can't even try to guess what this new topic is about. It would be great if it could 1) relate every OOD query to a wikipedia page 2) depending on the topic have a different reaction.
\item (17.05.19) A bot isn't able to \textbf{learn from feedbacks/corrections on the spot}. So it will repetitively do the same mistakes in a conversation. Maybe one could add an intent ``correction" and when this comes up, one would ask for more details and depending on the answer, change the policy used.
\item (09.05.19) In a conversation with a real human, a person will sometimes mention some vaguely related facts, just for the pleasure of speaking, in parentheses or even by orienting the conversation toward a brand new topic. Our bot only reacts to requests. We could improve that by adding the possibility for the bot to detect potential additional topics of interest of the user depending on information he or she gave, without having the user ask for it. So \textbf{proactive instead of only responsive}.
\item (08.05.19) I get the feeling that a bot can \textbf{focus only on one task at the time} and keep track of only one topic. What if I want to make a parenthesis and come back to the first topic later?
\item (08.05.19) I don't see any \textbf{reasoning} in our app. Every decision seems to be based on a hard coded procedure. But what is exactly reasoning? There seem to be models like ESIM to be able to deduce if a sentence is a consequence of a previous sentence. But this is a limited kind of reasoning. Can we do more? Can we use machine learning to determine when to use reasoning?
\item (08.05.19) The bot's \textbf{general behavior/responses will always be the same from one user to the other} and from one session to the other. It would be nice if it was keeping track of its previous interactions and that it behavior evolved. A bot which would have to do some recommendation task could after a while suggest something different from the current tastes (predicted using a recommander system) of the user.
\item (08.05.19) A bot is \textbf{always polite and servile}. People generally don't react well to rude requests or comment. These should be handled.
\item (01.03.19) I'm not sure that a bot can easily \textbf{understand that it has done a mistake} and not repeat it again. If there is a term which is ambiguous, like ``backhoe" in the riggs app and the computer tries to react to meaning 1, and the user says ``no, I meant meaning 2", I wonder how the bot could understand.
\item (01.03.19) I wonder if a bot can \textbf{learn to fit its user need} while talking with him/her.
\end{enumerate}

\section{Journal}

\begin{loggentry}{30.04.18}{Chat bots: Tai, Xiaoice, Named entity recognition, A nice blog about NLP}
It seems that some fairly advanced chatbots already exist:\\
\href{https://en.wikipedia.org/wiki/Xiaoice}{Wiki: Xiaoice}\\
\href{https://en.wikipedia.org/wiki/Tay_(bot)}{Wiki: Tay}\\
\end{loggentry}

\begin{loggentry}{01.05.18}{Google assistant, Dialogflow (API.AI), some french companies making chatbots}
I discovered the company \textbf{Dialogflow} owned by google:\\
\href{https://en.wikipedia.org/wiki/Dialogflow}{Wiki: Dialogflow}\\
and also read about \textbf{Google assitant}:\\
\href{https://en.wikipedia.org/wiki/Google_Assistant}{Wiki: Goolge Assitant}\\
I also discovered the following french companies/start-ups specialized in chatbots:\\
\begin{itemize}
\item Zelros: \url{http://www.zelros.com/}
\item recast ai: \url{https://recast.ai/}
\item golembot: \url{http://golembot.net/}
\end{itemize}
\end{loggentry}

\begin{loggentry}{02.05.18}{A Coursera course to build your own bot}
Roman recommended this course about NLP:\\
\url{https://www.coursera.org/learn/language-processing}\\
In the description of the course, they say that the final project consist in building your own chatbot.
\end{loggentry}

\begin{loggentry}{09.01.19}{5 levels of Chat bots}

This page explains what are the 5 levels of chat bots. For now we are currently reaching level 3 (Google is at least):\\
\url{https://www.oreilly.com/ideas/the-next-generation-of-ai-assistants-in-enterprise}\\

\end{loggentry}

\begin{loggentry}{01.01.19}{Conversation One: The anatomy of a modern conversation application}

Vijeta shared this link which gives an idea of concepts like \textbf{ontology} (which from my understanding comes down to the definition of intents and entities related to the domain), and how to implement a DM using the context:

\url{https://conversation.one/2017/10/25/anatomy-modern-conversational-application/}

\end{loggentry}


\begin{loggentry}{06.01.19}{Rasa Core and Interactive learning}

In this article:\\
\url{https://blog.rasa.com/a-new-approach-to-conversational-software/}\\
it is explained that Rasa developped a way to create a DM using ``interractive learning" which is a kind of reinforcement learning with feedback at every message, to build a good probabilistic model. I guess that it is good for the intent classification. It seems to be quite easy to use.

\end{loggentry}


\begin{loggentry}{19.03.19}{Article detailing components of a chat bots (with shallow semantic parsing)}

Mijail shared this article:\\
\url{http://aclweb.org/anthology/D18-2027}\\
which presents the general architecture of a virtual assistant, decomposing it into:
\begin{enumerate}
\item Intent Classification (Domain Classifier + Intent Classifier)
\item Entity Recognition
\item Entity Resolution
\item Semantic Praser (Entity Role Classifier + Entity Group Parser)
\item Question Answerer
\item Dialogue Manager
\item Application Manager
\end{enumerate}

\end{loggentry}


\begin{loggentry}{14.04.19}{The rise of consciousness from Kurzgesagt}

In this video:\\
\url{https://www.youtube.com/watch?v=H6u0VBqNBQ8}\\
the guys of Kurzgesagt explain what are the different stages of consciousness. This could be helpful to help us design an intelligent robot. Here are the stages:\\
\begin{enumerate}
\item Unaware of its environment but receives input (food or not food). There is an inner process (here converting food into energy) which triggers reactions (like moving more when no food is (randomly) collected).
\item Same as before but with \textbf{receptors} which help it target its food, meaning that the inputs of these receptors affect its behaviour. They blindly follow the signals of their sensors giving them an idea of the direction in which to go.
\item Same as before but with more refined receptors like \textbf{eyes} which give information not only about the presence or absence of food but also about the rest of the environment and potential obstacles.
\item Same as before but with an ``\textbf{inner representation of the world}" allowing the creature to pursue food even if its sensors don't detect it anymore. This is linked to the gift of \textbf{memory}.
\item Same as before but with a \textbf{sense of time}. This means being able to visualize a reward which only exists in the future.
\item The next level is the pocession of \textbf{language}.
\end{enumerate}

\end{loggentry}

\begin{loggentry}{30.06.19}{Trying to install Rasa}

I tried to install Rasa but I had problems. I couldn't train models because I kept receiving the error
\begin{verbatim}
No module named 'tensorflow.keras'
\end{verbatim}
when I was entering
\begin{verbatim}
rasa init --no-prompt
\end{verbatim}
(which triggers the training with the basic data which is downloaded).\\
The error seems to be due to the fact that I was using python 3.5 instead of python 3.7. I had initially created the environment using
\begin{verbatim}
conda create -n Rasa python=3.5 pip
\end{verbatim}
The problem disappeared when I used 
\begin{verbatim}
conda create -n Rasa python=3.7
\end{verbatim}
instead.

I tried it and it works.\\

\textbf{Next:} I need to find some good data set.

\end{loggentry}

\end{document}


















































