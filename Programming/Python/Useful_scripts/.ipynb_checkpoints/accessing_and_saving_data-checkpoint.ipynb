{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing and saving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will try to gather some commands to read data from files, and save python objects or data into other files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I should learn how to load various kinds of objects:\n",
    "\n",
    "    1) saved python objects\n",
    "    2) excell sheets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading .csv files with basic Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one has a .csv file with two columns `domain` and `id_user` (the headers are on the first line) one can load into a list of string, each string representing a line, as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'Toy_data/toy_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "with open(FILE_NAME) as f:\n",
    "    for row in f:\n",
    "        l.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, one has then to process each line manually to split it into different entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line is stored as '\"a.com\",32\\n' with type <class 'str'> \n",
      "Second line is '\"a.com\",25\\n' and its type is <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print('First line is stored as {} with type {} '.format(repr(l[0]), type(l[0])))\n",
    "print('Second line is {} and its type is {}'.format(repr(l[1]), type(l[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading .csv files with csv library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This library has the advantage over the `.readline` method of directly splitting each line into a list of substrings (one for each column in a table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "with open(FILE_NAME) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        l.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line is stored as ['domain', 'user_id'] with type <class 'list'> \n",
      "Second line is ['a.com', '32'] and its type is <class 'list'>\n",
      "There are in total 6 lines in the file.\n"
     ]
    }
   ],
   "source": [
    "print('First line is stored as {} with type {} '.format(repr(l[0]), type(l[0])))\n",
    "print('Second line is {} and its type is {}'.format(repr(l[1]), type(l[1])))\n",
    "print('There are in total {} lines in the file.'.format(len(l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can actually give option to the readers, as explained here: https://docs.python.org/3.7/library/csv.html#csv-fmt-params In particular, this can be used to read other types of table formats like .tsv files.\n",
    "\n",
    "The following cell is equivalent to what was done above (using default parameters for the reader):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l = []\n",
    "with open(FILE_NAME) as f:\n",
    "    reader = csv.reader(f, delimiter=',', lineterminator='\\n')\n",
    "    for row in reader:\n",
    "        l.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First line is stored as ['domain', 'user_id'] with type <class 'list'> \n",
      "Second line is ['a.com', '32'] and its type is <class 'list'>\n",
      "There are in total 6 lines in the file.\n"
     ]
    }
   ],
   "source": [
    "print('First line is stored as {} with type {} '.format(repr(l[0]), type(l[0])))\n",
    "print('Second line is {} and its type is {}'.format(repr(l[1]), type(l[1])))\n",
    "print('There are in total {} lines in the file.'.format(len(l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to create a dictionary where each item of the dictionary corresponds to a column of the .csv file, we proceed as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {}\n",
    "col_names = []\n",
    "with open(FILE_NAME) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if d1:\n",
    "            for i, value in enumerate(row):\n",
    "                d1[col_names[i]].append(value)\n",
    "        else:\n",
    "            col_names = row\n",
    "            d1 = {col: [] for col in row}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'domain': ['a.com', 'b.com', 'a.com', 'a.com', 'b.com'], 'user_id': ['32', '21', '25', '21', '21']}\n"
     ]
    }
   ],
   "source": [
    "print(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead we want to create a list of ordered dictionaries, each dictionary representing one event/line, we can proceed as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_dict = []\n",
    "with open(FILE_NAME) as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        l_dict.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('domain', 'a.com'), ('user_id', '32')]), OrderedDict([('domain', 'b.com'), ('user_id', '21')]), OrderedDict([('domain', 'a.com'), ('user_id', '25')]), OrderedDict([('domain', 'a.com'), ('user_id', '21')]), OrderedDict([('domain', 'b.com'), ('user_id', '21')])]\n"
     ]
    }
   ],
   "source": [
    "print(l_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by default, the elements of the first row are used as the field names for the dictionary. So the above code is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_dict = []\n",
    "with open(FILE_NAME) as f:\n",
    "    reader = csv.DictReader(f, fieldnames=['domain', 'user_id'])\n",
    "    for i, row in enumerate(reader):\n",
    "        if i>0:\n",
    "            l_dict.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OrderedDict([('domain', 'a.com'), ('user_id', '32')]), OrderedDict([('domain', 'b.com'), ('user_id', '21')]), OrderedDict([('domain', 'a.com'), ('user_id', '25')]), OrderedDict([('domain', 'a.com'), ('user_id', '21')]), OrderedDict([('domain', 'b.com'), ('user_id', '21')])]\n"
     ]
    }
   ],
   "source": [
    "print(l_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Actually, it seems good to encapsulate the reading of the file inside a function or a class as explained here: https://medium.com/district-data-labs/simple-csv-data-wrangling-with-python-3496aa5d0a5e\n",
    "\n",
    "The page also provide good implementation of a class to read a csv table and avoid loading it entirely on the RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Python objects with Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found the next piece of code here: https://wiki.python.org/moin/UsingPickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a dictionary into a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "favorite_color = { \"lion\": \"yellow\", \"kitty\": \"red\" }\n",
    "pickle.dump( favorite_color, open( \"save.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "favorite_color2 = pickle.load( open( \"save.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Loading a csv table with numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a csv table contains only numeric values, one can use numpy to load it directly into a numpy array. There are plenty of options, in particular, one can choose what to do with missing values and which column to select. This being said, I don't see many advantages over using the csv library.\n",
    "\n",
    "**Note:** This is not memory efficient as the whole data is loaded on the RAM at once. It should hence be avoided when dealing with big files (as expained here: https://medium.com/district-data-labs/simple-csv-data-wrangling-with-python-3496aa5d0a5e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME2 = '/home/aritz/Documents/CS_Programming_Machine_Learning/Programming/Python/Useful_scripts/Toy_data/table_numbers.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FILE_NAME2) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, line in enumerate(reader):\n",
    "        if i == 0:\n",
    "            headers = line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['col1', 'col2', 'col3']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt(fname=FILE_NAME2, delimiter=',', skip_header=1, missing_values='NA', filling_values=0,\n",
    "                     dtype='float64', names=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(112., 0.13, 3.), (117., 1.2 , 1.), ( 54., 0.77, 2.),\n",
       "       ( 99., 0.5 , 2.), (  0., 1.4 , 1.)],\n",
       "      dtype=[('col1', '<f8'), ('col2', '<f8'), ('col3', '<f8')])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next task**: Look how I loaded things in my sentiment analysis project, in NLP coursera, in Rossman fastai."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
